# final_ML_personal
Nguyá»…n Thá»‹ Thu Há»“ng - 52100962

# Dá»° ÃN CUá»I Ká»²
# NHáº¬P MÃ”N Há»ŒC MÃY
BÃ€I 1: TrÃ¬nh bÃ y má»™t bÃ i nghiÃªn cá»©u, Ä‘Ã¡nh giÃ¡ cá»§a em vá» cÃ¡c váº¥n Ä‘á» sau:
1.	TÃ¬m hiá»ƒu, so sÃ¡nh cÃ¡c phÆ°Æ¡ng phÃ¡p Optimizer trong huáº¥n luyá»‡n mÃ´ hÃ¬nh há»c mÃ¡y;
2.	TÃ¬m hiá»ƒu vá» Continual Learning vÃ  Test Production khi xÃ¢y dá»±ng má»™t giáº£i phÃ¡p há»c mÃ¡y Ä‘á»ƒ giáº£i quyáº¿t má»™t bÃ i toÃ¡n nÃ o Ä‘Ã³;

## CHÆ¯Æ NG 1 â€“ Tá»”NG QUAN Vá»€ Há»ŒC MÃY
### 1.1 Há»c mÃ¡y lÃ  gÃ¬?
Machine learning (há»c mÃ¡y hay mÃ¡y há»c) lÃ  má»™t nhÃ¡nh con cá»§a trÃ­ tuá»‡ nhÃ¢n táº¡o (AI) vÃ  khoa há»c mÃ¡y tÃ­nh. Machine learning sá»­ dá»¥ng dá»¯ liá»‡u, thuáº­t toÃ¡n Ä‘áº§u vÃ o Ä‘á»ƒ tá»± xá»­ lÃ½ cÃ¡c váº¥n Ä‘á» vÃ  liÃªn tá»¥c tá»‘i Æ°u Ä‘á»ƒ táº¡o ra nhá»¯ng phÆ°Æ¡ng Ã¡n xá»­ lÃ½ má»›i hiá»‡u quáº£ hÆ¡n, phÃ¹ há»£p hÆ¡n, giá»‘ng nhÆ° cÃ¡ch thá»©c tá»± há»c cá»§a nÃ£o bá»™ con ngÆ°á»i.

Má»™t cÃ¡ch tá»•ng quÃ¡t, trong cuá»‘n sÃ¡ch Machine Learning cá»§a tÃ¡c giáº£ Tom Mitchell xuáº¥t báº£n nÄƒm 1997, há»c mÃ¡y Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a nhÆ° sau: â€œA computer program is said to learn to perform a task T from experience E, if its performance at task T, as measured by a performance metric P, improves with experience E over timeâ€ (Má»™t chÆ°Æ¡ng trÃ¬nh mÃ¡y tÃ­nh Ä‘Æ°á»£c cho lÃ  há»c Ä‘á»ƒ thá»±c hiá»‡n má»™t nhiá»‡m vá»¥ T tá»« kinh nghiá»‡m E, náº¿u hiá»‡u suáº¥t thá»±c hiá»‡n cÃ´ng viá»‡c T cá»§a nÃ³ Ä‘Æ°á»£c Ä‘o bá»Ÿi chá»‰ sá»‘ hiá»‡u suáº¥t P vÃ  Ä‘Æ°á»£c cáº£i thiá»‡n bá»Ÿi kinh nghiá»‡m E theo thá»i gian).
KhÃ¡c biá»‡t giá»¯a chÆ°Æ¡ng trÃ¬nh láº­p trÃ¬nh truyá»n thá»‘ng vÃ  há»c mÃ¡y.

<img src="picture/1.1.png">

HÃ¬nh 1.1 Minh há»a chÆ°Æ¡ng trÃ¬nh láº­p trÃ¬nh truyá»n thá»‘ng

<img src="picture/1.1.1.png">

HÃ¬nh 1.1 Minh há»a há»c mÃ¡y

Thá»‘ng kÃª vÃ  dá»± Ä‘oÃ¡n lÃ  hai má»¥c Ä‘Ã­ch chÃ­nh cá»§a viá»‡c Ã¡p dá»¥ng machine learning vÃ¬ tháº¿ há»‡ thá»‘ng nÃ y Ä‘Æ°á»£c thiáº¿t káº¿ vá»›i kháº£ nÄƒng tá»± nghiÃªn cá»©u, cáº£i tiáº¿n báº£n thÃ¢n dá»±a trÃªn nhá»¯ng nguyÃªn lÃ½ Ä‘Æ°á»£c láº­p trÃ¬nh ban Ä‘áº§u. Trong nhiá»u trÆ°á»ng há»£p machine learning sáº½ tá»± Ä‘á» xuáº¥t ra giáº£i phÃ¡p tá»‘i Æ°u mÃ  khÃ´ng cáº§n Ä‘Æ°á»£c láº­p trÃ¬nh trÆ°á»›c. Do Ä‘Ã³, cÃ³ thá»ƒ nÃ³i Machine Learning giá»‘ng nhÆ° má»™t ngÆ°á»i lao Ä‘á»™ng vá»›i kháº£ nÄƒng tá»± há»c, hoÃ n thiá»‡n vÃ  giÃ u kinh nghiá»‡m hÆ¡n theo thá»i gian.

Trong nhá»¯ng nÄƒm gáº§n Ä‘Ã¢y, khi mÃ  kháº£ nÄƒng tÃ­nh toÃ¡n cá»§a cÃ¡c mÃ¡y tÃ­nh Ä‘Æ°á»£c nÃ¢ng lÃªn má»™t táº§m cao má»›i vÃ  lÆ°á»£ng dá»¯ liá»‡u khá»•ng lá»“ Ä‘Æ°á»£c thu tháº­p bá»Ÿi cÃ¡c hÃ£ng cÃ´ng nghá»‡ lá»›n, Machine Learning Ä‘Ã£ tiáº¿n thÃªm má»™t bÆ°á»›c dÃ i vÃ  má»™t lÄ©nh vá»±c má»›i Ä‘Æ°á»£c ra Ä‘á»i gá»i lÃ  Deep Learning (Há»c SÃ¢u). Deep Learning Ä‘Ã£ giÃºp mÃ¡y tÃ­nh thá»±c thi nhá»¯ng viá»‡c tÆ°á»Ÿng chá»«ng nhÆ° khÃ´ng thá»ƒ vÃ o 10 nÄƒm trÆ°á»›c: phÃ¢n loáº¡i cáº£ ngÃ n váº­t thá»ƒ khÃ¡c nhau trong cÃ¡c bá»©c áº£nh, tá»± táº¡o chÃº thÃ­ch cho áº£nh, báº¯t chÆ°á»›c giá»ng nÃ³i vÃ  chá»¯ viáº¿t cá»§a con ngÆ°á»i, giao tiáº¿p vá»›i con ngÆ°á»i, hay tháº­m chÃ­ cáº£ sÃ¡ng tÃ¡c vÄƒn hay Ã¢m nháº¡c, â€¦

<img src="picture/1.2.png">

HÃ¬nh 1.2 Má»‘i quan há»‡ giá»¯a AI, Machine Learning vÃ  Deep Learning

(Nguá»“n: Whatâ€™s the Difference Between Artificial Intelligence, Machine Learning, and Deep Learning?)

### 1.2 PhÃ¢n loáº¡i Há»c mÃ¡y:

Dá»±a trÃªn cÃ¡c tiÃªu chÃ­ khÃ¡c nhau, ngÆ°á»i ta cÃ³ thá»ƒ phÃ¢n loáº¡i cÃ¡c thuáº­t toÃ¡n Há»c mÃ¡y theo nhiá»u cÃ¡ch khÃ¡c nhau. 

#### 1.2.1 PhÃ¢n loáº¡i theo váº¥n Ä‘á», nhiá»‡m vá»¥ cáº§n giáº£i quyáº¿t:

Dá»±a vÃ o váº¥n Ä‘á», nhiá»‡m vá»¥ cáº§n giáº£i quyáº¿t cá»§a thuáº­t toÃ¡n, ngÆ°á»i ta phÃ¢n loáº¡i cÃ¡c thuáº­t toÃ¡n Há»c mÃ¡y thÃ nh ba loáº¡i:

1.	Há»“i quy (Regression): Giáº£i quyáº¿t bÃ i toÃ¡n dá»± Ä‘oÃ¡n giÃ¡ trá»‹ má»™t Ä‘áº¡i lÆ°á»£ng nÃ o Ä‘Ã³ dá»±a vÃ o giÃ¡ trá»‹ cá»§a cÃ¡c Ä‘áº¡i lÆ°á»£ng liÃªn quan. VÃ­ dá»¥, dá»±a vÃ o cÃ¡c Ä‘áº·c Ä‘iá»ƒm nhÆ° diá»‡n tÃ­ch, sá»‘ phÃ²ng, khoáº£ng cÃ¡ch tá»›i trung tÃ¢mâ€¦Ä‘á»ƒ dá»± Ä‘oÃ¡n giÃ¡ trá»‹ cÄƒn nhÃ .
2.	PhÃ¢n lá»›p (Classification): Giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n nháº­n dáº¡ng xem má»™t Ä‘á»‘i tÆ°á»£ng thuá»™c lá»›p nÃ o trong sá»‘ cÃ¡c lá»›p cho trÆ°á»›c. VÃ­ dá»¥, bÃ i toÃ¡n nháº­n diá»‡n chá»¯ viáº¿t, bÃ i toÃ¡n phÃ¢n loáº¡i emailâ€¦thuá»™c cÃ¡c thuáº­t toÃ¡n phÃ¢n lá»›p.
3.	PhÃ¢n cá»¥m (Clustering): Ã tÆ°á»Ÿng cÆ¡ báº£n giá»‘ng vá»›i cÃ¡c thuáº­t toÃ¡n phÃ¢n lá»›p, sá»± khÃ¡c biá»‡t lÃ  á»Ÿ chá»—, trong cÃ¡c bÃ i toÃ¡n phÃ¢n cá»¥m, cÃ¡c cá»¥m chÆ°a Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh trÆ°á»›c vÃ  thuáº­t toÃ¡n pháº£i tá»± khÃ¡m phÃ¡ vÃ  phÃ¢n cá»¥m dá»¯ liá»‡u.

<img src="picture/1.3.png">

HÃ¬nh 1.3 CÃ¡c giáº£i thuáº­t Há»c mÃ¡y

(Nguá»“n: https://tailieuhay.vn/tai-lieu/bai-giang-hoc-may-bai-5-cay-phan-loai-va-hoi-quy-nguyen-thanh-tung-7733/ )

#### 1.2.2 PhÃ¢n loáº¡i theo cÃ¡ch mÃ¡y tÃ­nh há»c:

Dá»±a trÃªn cÃ¡ch mÃ¡y tÃ­nh há»c, ngÆ°á»i ta chia cÃ¡c thuáº­t toÃ¡n Há»c mÃ¡y thÃ nh ba loáº¡i:

1.	Há»c táº­p dÆ°á»›i sá»± giÃ¡m sÃ¡t (Supervised learning): Con ngÆ°á»i sáº½ láº­p trÃ¬nh dá»¯ liá»‡u Ä‘áº§u vÃ o bao gá»“m cáº£ cÃ¡ch thá»©c vÃ  phÆ°Æ¡ng Ã¡n mÃ  con ngÆ°á»i mong muá»‘n. PhÆ°Æ¡ng Ã¡n vÃ  Ä‘Ã¡p Ã¡n sáº½ Ä‘Æ°á»£c gáº¯n nhÃ£n, sáº¯p xáº¿p sáºµn vÃ  Machine Learning chá»‰ cáº§n rÃ  soÃ¡t vÃ  tráº£ ra Ä‘Ãºng káº¿t quáº£ cÃ³ trong bá»™ dá»¯ liá»‡u Ä‘Ã£ cÃ³. Tin nháº¯n rÃ¡c Ä‘áº¿n tá»« 1 sá»‘ nguá»“n sáº½ tá»± Ä‘á»™ng Ä‘Æ°á»£c tÃ¡ch ra khá»i há»™p thÆ° chÃ­nh lÃ  á»©ng dá»¥ng cá»§a machine learning giÃºp phÃ¢n loáº¡i tin nháº¯n trÃªn email.
2.	Há»c táº­p mÃ  khÃ´ng giÃ¡m sÃ¡t (Unsupervised learning): Machine learning chá»‰ Ä‘Æ°á»£c cung cáº¥p cÃ¡c thuáº­t toÃ¡n, cÃ´ng cá»¥ Ä‘á»ƒ tá»± xá»­ lÃ½ mÃ  khÃ´ng biáº¿t trÆ°á»›c káº¿t quáº£. Dá»… tháº¥y nháº¥t viá»‡c á»©ng dá»¥ng cá»§a phÃ¢n loáº¡i nÃ y Ä‘Ã³ lÃ  cÃ¡ nhÃ¢n hÃ³a tráº£i nghiá»‡m khÃ¡ch hÃ ng.Dá»¯ liá»‡u Ä‘áº§u vÃ o bao gá»“m hÃ nh vi, lá»‹ch sá»­ mua mua hÃ ng vÃ  há»‡ thá»‘ng sáº½ dá»± Ä‘oÃ¡n nhá»¯ng sáº£n pháº©m phÃ¹ há»£p vÃ  Ä‘á» xuáº¥t riÃªng cho tá»«ng khÃ¡ch hÃ ng.
3.	Há»c táº­p Ä‘Æ°á»£c giÃ¡m sÃ¡t bÃ¡n pháº§n (Semi-supervised learning): ÄÃ¢y lÃ  phÃ¢n loáº¡i náº±m á»Ÿ giá»¯a cá»§a 2 phÃ¢n loáº¡i trÃªn khi nÃ y dá»¯ liá»‡u Ä‘áº§u vÃ o lÃ  1 há»—n há»£p bao gá»“m cáº£ phÆ°Æ¡ng phÃ¡p láº«n Ä‘Ã¡p Ã¡n. Äiá»ƒm khÃ¡c biá»‡t á»Ÿ Ä‘Ã¢y lÃ  phÆ°Æ¡ng Ã¡n vÃ  Ä‘Ã¡p Ã¡n chÆ°a Ä‘Æ°á»£c nhÃ³m láº¡i thÃ nh tá»«ng bá»™. NhÆ° váº­y machine learning pháº£i tá»± tÃ¬m ra cÃ¡ch giáº£i nÃ o tÆ°Æ¡ng thÃ­ch vá»›i Ä‘Ã¡p Ã¡n nÃ o trong bá»™ dá»¯ liá»‡u sáºµn cÃ³.

### 1.3 CÃ¡c bÆ°á»›c cÆ¡ báº£n thá»±c hiá»‡n má»™t thuáº­t toÃ¡n Há»c mÃ¡y:

NhÃ¬n chung, viá»‡c thá»±c hiá»‡n má»™t thuáº­t toÃ¡n Há»c mÃ¡y thÆ°á»ng tráº£i qua cÃ¡c bÆ°á»›c cÆ¡ báº£n sau:

1.	Thu tháº­p dá»¯ liá»‡u â€“ Gathering data/Data collection
2.	Tiá»n xá»­ lÃ½ dá»¯ liá»‡u â€“ Data preprocessing
    1.	TrÃ­ch xuáº¥t dá»¯ liá»‡u â€“ data extraction
    2.	LÃ m sáº¡ch dá»¯ liá»‡u â€“ data cleaning
    3.	Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u â€“ Data transformation
    4.	Chuáº©n hÃ³a dá»¯ liá»‡u â€“ Data normalization
    5.	TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng â€“ Feature extraction
3.	PhÃ¢n tÃ­ch dá»¯ liá»‡u â€“ Data analysis
4.	XÃ¢y dá»±ng mÃ´ hÃ¬nh mÃ¡y há»c â€“ Model building
5.	Huáº¥n luyá»‡n mÃ´ hÃ¬nh â€“ Model training
6.	ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh â€“ Model evaluation
   
Trong táº¥t cáº£ cÃ¡c bÆ°á»›c thÃ¬ viá»‡c thu tháº­p dá»¯ liá»‡u, tiá»n xá»­ lÃ½ vÃ  xÃ¢y dá»±ng bá»™ dá»¯ liá»‡u lÃ  tá»‘n nhiá»u thá»i gian vÃ  cÃ´ng sá»©c nháº¥t. ÄÃ¢y lÃ  bÆ°á»›c quan trá»ng, cÃ³ áº£nh hÆ°á»Ÿng ráº¥t nhiá»u Ä‘áº¿n hiá»‡u quáº£ cá»§a thuáº­t toÃ¡n Há»c mÃ¡y.

### 1.4 á»¨ng dá»¥ng cá»§a Há»c mÃ¡y:

á»¨ng dá»¥ng tá»•ng quÃ¡t:

â€¢	Xá»­ lÃ½ áº£nh
â€¢	PhÃ¢n tÃ­ch vÄƒn báº£n
â€¢	Khai phÃ¡ dá»¯ liá»‡u

á»¨ng dá»¥ng trong thá»±c táº¿:

â€¢	Giáº£i mÃ£ thá»‹ trÆ°á»ng tÃ i chÃ­nh

â€¢	Thay Ä‘á»•i cá»¥c diá»‡n ngÃ nh nÃ´ng nghiá»‡p

â€¢	NÃ¢ng cao hiá»‡u quáº£ vÃ  cáº£i thiá»‡n cháº¥t lÆ°á»£ng dá»‹ch vá»¥ ngÃ nh y táº¿

â€¢	CÆ¡ quan nhÃ  nÆ°á»›c cÃ³ thá»ƒ quáº£n lÃ½ tráº­t tá»± xÃ£ há»™i vÃ  Ä‘áº£m báº£o tÃ¬nh hÃ¬nh phÃ¡t triá»ƒn Ä‘áº¥t nÆ°á»›c

## CHÆ¯Æ NG 2 â€“ CÃC PHÆ¯Æ NG PHÃP OPTIMIZER
### 2.1 Tá»•ng quan vá» Optimizer
#### 2.1.1 Optimizer lÃ  gÃ¬?
Optimizer hay Thuáº­t toÃ¡n tá»‘i Æ°u lÃ  cÆ¡ sá»Ÿ Ä‘á»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh Neural Network vá»›i má»¥c Ä‘Ã­ch â€œhá»câ€ Ä‘Æ°á»£c cÃ¡c feature (hay pattern) cá»§a dá»¯ liá»‡u Ä‘áº§u vÃ o, Ä‘á»ƒ tá»« Ä‘Ã³ cÃ³ thá»ƒ tÃ¬m má»™t táº­p cÃ¡c trá»ng sá»‘ (weights â€“ w) vÃ  ngÆ°á»¡ng (bias â€“ b) phÃ¹ há»£p hÆ¡n Ä‘á»ƒ tá»‘i Æ°u hÃ³a mÃ´ hÃ¬nh. 

VÃ  cÃ³ thá»ƒ nÃ³i cÃ¡c thuáº­t toÃ¡n tá»‘i Æ°u (Optimizition Algorithm) lÃ  má»™t trong nhá»¯ng â€œháº¡t nhÃ¢nâ€ máº¡nh máº½ cá»§a háº§u háº¿t thuáº­t toÃ¡n Machine Learning. ÄÃ¢y má»™t quy trÃ¬nh Ä‘Æ°á»£c thá»±c hiá»‡n láº·p Ä‘i láº·p láº¡i báº±ng cÃ¡ch so sÃ¡nh cÃ¡c giáº£i phÃ¡p khÃ¡c nhau cho Ä‘áº¿n khi tÃ¬m tháº¥y má»™t giáº£i phÃ¡p tá»‘i Æ°u hoáº·c thá»a Ä‘Ã¡ng.

Äá»‘i vá»›i ká»¹ thuáº­t há»c sÃ¢u nÃ³i riÃªng, thuáº­t toÃ¡n tá»‘i Æ°u lÃ  cÃ¡c ká»¹ thuáº­t giÃºp xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh máº¡ng nÆ¡-ron Ä‘á»ƒ tá»‘i Æ°u hÃ³a Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh máº¡ng.

<img src="picture/2.1.png">

HÃ¬nh 2.1 Minh há»a thuáº­t toÃ¡n tá»‘i Æ°u (Optimizer)

#### 2.1.2 Vai trÃ² cá»§a thuáº­t toÃ¡n tá»‘i Æ°u

Trong thuáº­t toÃ¡n há»c mÃ¡y nÃ³i chung vÃ  ká»¹ thuáº­t há»c sÃ¢u nÃ³i riÃªng, thuáº­t toÃ¡n tá»‘i Æ°u hÃ³a (Optimizer) lÃ  má»™t khÃ¢u quan trá»ng khÃ´ng thá»ƒ thiáº¿u. QuÃ¡ trÃ¬nh tá»‘i Æ°u hÃ³a thá»±c hiá»‡n xÃ¡c Ä‘á»‹nh hÃ m máº¥t mÃ¡t (loss function) vÃ  sau Ä‘Ã³ tá»‘i thiá»ƒu hÃ³a hÃ m trÃªn báº±ng cÃ¡ch sá»­ dá»¥ng hÃ m tá»‘i Æ°u. Cá»¥ thá»ƒ, thÃ´ng qua viá»‡c cáº­p nháº­t cÃ¡c tham sá»‘ cá»§a mÃ´ hÃ¬nh (w, b) vÃ  Ä‘Ã¡nh giÃ¡ láº¡i hÃ m máº¥t mÃ¡t vá»›i má»™t tá»‰ lá»‡ há»c (learning rate) xÃ¡c Ä‘á»‹nh, quÃ¡ trÃ¬nh tá»‘i Æ°u giÃºp mÃ´ hÃ¬nh tÆ°Æ¡ng thÃ­ch tá»‘t hÆ¡n vá»›i táº­p dá»¯ liá»‡u Ä‘Æ°á»£c Ä‘Ã o táº¡o.

##### 2.1.2.1 HÃ m máº¥t mÃ¡t (Loss function)

HÃ m máº¥t mÃ¡t (Loss function) lÃ  má»™t phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡ Ä‘á»™ hiá»‡u quáº£ cá»§a thuáº­t toÃ¡n â€œhá»câ€ cho mÃ´ hÃ¬nh trÃªn táº­p dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng. 
HÃ m máº¥t mÃ¡t tráº£ vá» má»™t sá»‘ thá»±c khÃ´ng Ã¢m thá»ƒ hiá»‡n sá»± chÃªnh lá»‡ch giá»¯a hai Ä‘áº¡i lÆ°á»£ng: 

â€¢	a: nhÃ£n Ä‘Æ°á»£c dá»± Ä‘oÃ¡n

â€¢	y: nhÃ£n Ä‘Ãºng

Báº£n thÃ¢n hÃ m máº¥t mÃ¡t chÃ­nh lÃ  má»™t cÆ¡ cháº¿ thÆ°á»Ÿng-pháº¡t, mÃ´ hÃ¬nh sáº½ pháº£i Ä‘Ã³ng pháº¡t má»—i láº§n dá»± Ä‘oÃ¡n sai vÃ  má»©c pháº¡t tá»‰ lá»‡ thuáº­n vá»›i Ä‘á»™ lá»›n sai sÃ³t. 
Trong má»i bÃ i toÃ¡n há»c cÃ³ giÃ¡m sÃ¡t, má»¥c tiÃªu luÃ´n bao gá»“m giáº£m tá»•ng má»©c pháº¡t pháº£i Ä‘Ã³ng. Trong trÆ°á»ng há»£p lÃ½ tÆ°á»Ÿng a = y, hÃ m máº¥t mÃ¡t sáº½ tráº£ vá» giÃ¡ trá»‹ cá»±c tiá»ƒu báº±ng 0. 
Hai hÃ m máº¥t mÃ¡t thÆ°á»ng xuyÃªn Ä‘Æ°á»£c sá»­ dá»¥ng trong máº¡ng nÆ¡-ron: 

â€¢	MSE (Mean Squared Error)

â€¢	Cross Entropy

##### 2.1.2.2 Tá»‰ lá»‡ há»c (Learning rate)

Learning rate hay tá»‰ lá»‡ há»c lÃ  má»™t thÃ´ng sá»‘ quan trá»ng trong viá»‡c quyáº¿t Ä‘á»‹nh tá»‘c Ä‘á»™ há»c cá»§a máº¡ng nÆ¡-ron. Tá»‘c Ä‘á»™ há»c Ä‘Æ°á»£c thá»ƒ hiá»‡n báº±ng sá»± thay Ä‘á»•i giÃ¡ trá»‹ cáº­p nháº­t trá»ng sá»‘ (weights - w) trong cÃ¡c chu ká»³ há»c. TÃ¹y theo má»¥c Ä‘Ã­ch cá»§a mÃ´ hÃ¬nh mÃ  tÄƒng/ giáº£m tá»‰ lá»‡ há»c. 

Tá»‰ lá»‡ há»c cÃ ng cao thÃ¬ giÃºp mÃ´ hÃ¬nh há»c khÃ¡ nhanh vÃ  tiáº¿t kiá»‡m Ä‘Æ°á»£c thá»i gian huáº¥n luyá»‡n, tuy nhiÃªn viá»‡c tá»‰ lá»‡ há»c lá»›n Ä‘á»“ng nghÄ©a vá»›i viá»‡c sá»± thay Ä‘á»•i trá»ng sá»‘ (weights - w) vÃ  tham sá»‘ ngÆ°á»¡ng (bias - b) cÃ ng lá»›n, mÃ´ hÃ¬nh khÃ´ng á»•n Ä‘á»‹nh, má»™t sá»‘ chu ká»³ há»c cÃ³ sá»± dao Ä‘á»™ng máº¡nh á»Ÿ tá»‰ lá»‡ nháº­n dáº¡ng Ä‘Ãºng hay nÃ³i cÃ¡ch khÃ¡c lÃ  thuáº­t toÃ¡n khÃ´ng Ä‘Æ°á»£c tá»‘i Æ°u vÃ  ngÆ°á»£c láº¡i Ä‘á»‘i vá»›i tá»‰ lá»‡ há»c nhá».

#### 2.1.3 Yáº¿u tá»‘ Ä‘Ã¡nh giÃ¡ má»™t thuáº­t toÃ¡n tá»‘i Æ°u

Má»™t vÃ i cÃ¡c yáº¿u tá»‘ hay Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ má»™t thuáº­t toÃ¡n tá»‘i Æ°u (Optimizer):

â€¢	Há»™i tá»¥ nhanh (trong quÃ¡ trÃ¬nh train)

â€¢	Sá»± tá»•ng quÃ¡t hÃ³a cao (váº«n nháº­n dáº¡ng Ä‘Æ°á»£c nhá»¯ng máº«u chÆ°a tá»«ng Ä‘Æ°á»£c huáº¥n luyá»‡n)

â€¢	Äá»™ chÃ­nh xÃ¡c cao

### 2.2 Má»™t sá»‘ thuáº­t toÃ¡n tá»‘i Æ°u (Optimization Algorithms)

Má»™t sá»‘ thuáº­t toÃ¡n tá»‘i Æ°u phá»• biáº¿n:

1.	Gradient Descent
2.	SGD vá»›i Ä‘á»™ng lÆ°á»£ng
3.	RMSProp
4.	Adagrad
5.	Adadelta
6.	Adam
7.	AdamW
8.	AMSGrad
   
#### 2.2.1 Gradient Descent (GD)

Gradient Descent (GD) lÃ  thuáº­t toÃ¡n tÃ¬m tá»‘i Æ°u chung cho cÃ¡c hÃ m sá»‘. Ã tÆ°á»Ÿng chung cá»§a GD lÃ  Ä‘iá»u chá»‰nh cÃ¡c tham sá»‘ Ä‘á»ƒ láº·p Ä‘i láº·p láº¡i thÃ´ng qua má»—i dá»¯ liá»‡u huáº¥n luyá»‡n Ä‘á»ƒ giáº£m thiá»ƒu hÃ m chi phÃ­. 

ğ‘¤(ğ‘˜+1) = ğ‘¤(ğ‘˜) âˆ’ ğœ‚ âˆ‡ğ‘¤ ğ½(ğ‘¤(ğ‘˜) )

Trong Ä‘Ã³:

â€¢	ğ‘¤(ğ‘˜) : tham sá»‘ táº¡i bÆ°á»›c cáº­p nháº­t táº¡i lá»›p k

â€¢	Î—: tá»‰ lá»‡ há»c

â€¢	ğ½(ğ‘¤): hÃ m lá»—i

â€¢	âˆ‡ğ‘¤ ğ½(ğ‘¤ (ğ‘˜)): Ä‘áº¡o hÃ m cá»§a hÃ m lá»—i táº¡i Ä‘iá»ƒm ğ‘¤(ğ‘˜)

VÃ­ dá»¥:

```sh
from __future__ import division, print_function, unicode_literals
import math
import numpy as np 
import matplotlib.pyplot as plt

def grad(x):
    return 2*x+ 5*np.cos(x)

def cost(x):
    return x**2 + 5*np.sin(x)

def myGD1(eta, x0):
    x = [x0]
    for it in range(100):
        x_new = x[-1] - eta*grad(x[-1])
        if abs(grad(x_new)) < 1e-3:
            break
        x.append(x_new)
    return (x, it)

(x1, it1) = myGD1(.1, -5)
(x2, it2) = myGD1(.1, 5)
print('Solution x1 = %f, cost = %f, obtained after %d iterations'%(x1[-1], cost(x1[-1]), it1))
print('Solution x2 = %f, cost = %f, obtained after %d iterations'%(x2[-1], cost(x2[-1]), it2))
```
Káº¿t quáº£:

```sh
Solution x1 = -1.110667, cost = -3.246394, obtained after 11 iterations
Solution x2 = -1.110341, cost = -3.246394, obtained after 29 iterations
```
ï¶	Äiá»ƒm khá»Ÿi táº¡o khÃ¡c nhau

Sau khi cÃ³ cÃ¡c hÃ m cáº§n thiáº¿t, tÃ´i thá»­ tÃ¬m nghiá»‡m vá»›i cÃ¡c Ä‘iá»ƒm khá»Ÿi táº¡o khÃ¡c nhau lÃ  x0 = âˆ’5 vÃ  x0 = 5.

<img src="picture/2.2.png"> <img src="picture/2.2.1.png">

HÃ¬nh 2.2 Minh há»a thuáº­t toÃ¡n GD vá»›i Ä‘iá»ƒm khá»Ÿi táº¡o khÃ¡c nhau

Tá»« hÃ¬nh minh há»a trÃªn ta tháº¥y ráº±ng á»Ÿ hÃ¬nh bÃªn trÃ¡i, tÆ°Æ¡ng á»©ng vá»›i x0 =âˆ’5, nghiá»‡m há»™i tá»¥ nhanh hÆ¡n, vÃ¬ Ä‘iá»ƒm ban Ä‘áº§u x0 gáº§n vá»›i nghiá»‡m x* â‰ˆ âˆ’1 hÆ¡n. HÆ¡n ná»¯a, vá»›i x0 =5 á»Ÿ hÃ¬nh bÃªn pháº£i, Ä‘Æ°á»ng Ä‘i cá»§a nghiá»‡m cÃ³ chá»©a má»™t khu vá»±c cÃ³ Ä‘áº¡o hÃ m khÃ¡ nhá» gáº§n Ä‘iá»ƒm cÃ³ hoÃ nh Ä‘á»™ báº±ng 2. 

ïƒ°	Äiá»u nÃ y khiáº¿n cho thuáº­t toÃ¡n la cÃ  á»Ÿ Ä‘Ã¢y khÃ¡ lÃ¢u. Khi vÆ°á»£t qua Ä‘Æ°á»£c Ä‘iá»ƒm nÃ y thÃ¬ má»i viá»‡c diá»…n ra ráº¥t tá»‘t Ä‘áº¹p.





